{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "root = './data'\n",
    "\n",
    "def get_data(dataset, batch_size):\n",
    "\n",
    "    # Get MNIST dataset.\n",
    "    if dataset == 'MNIST':\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(28),\n",
    "            transforms.CenterCrop(28),\n",
    "            transforms.ToTensor()])\n",
    "\n",
    "        dataset = dsets.MNIST(root+'mnist/', train='train', \n",
    "                                download=True, transform=transform)\n",
    "\n",
    "    # Get FashionMNIST dataset.\n",
    "    elif dataset == 'FashionMNIST':\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(28),\n",
    "            transforms.CenterCrop(28),\n",
    "            transforms.ToTensor()])\n",
    "\n",
    "        dataset = dsets.FashionMNIST(root+'fashionmnist/', train='train', \n",
    "                                download=True, transform=transform)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tconv1 = nn.ConvTranspose2d(74, 1024, 1, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(1024)\n",
    "\n",
    "        self.tconv2 = nn.ConvTranspose2d(1024, 128, 7, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.tconv3 = nn.ConvTranspose2d(128, 64, 4, 2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.tconv4 = nn.ConvTranspose2d(64, 1, 4, 2, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.tconv1(x)))\n",
    "        x = F.relu(self.bn2(self.tconv2(x)))\n",
    "        x = F.relu(self.bn3(self.tconv3(x)))\n",
    "\n",
    "        img = torch.sigmoid(self.tconv4(x))\n",
    "\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, 4, 2, 1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 1024, 7, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.1, inplace=True)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.1, inplace=True)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.1, inplace=True)\n",
    "\n",
    "        return x\n",
    "\n",
    "class DHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(1024, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = torch.sigmoid(self.conv(x))\n",
    "\n",
    "        return output\n",
    "\n",
    "class QHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1024, 128, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv_disc = nn.Conv2d(128, 10, 1)\n",
    "        self.conv_mu = nn.Conv2d(128, 2, 1)\n",
    "        self.conv_var = nn.Conv2d(128, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)), 0.1, inplace=True)\n",
    "\n",
    "        disc_logits = self.conv_disc(x).squeeze()\n",
    "\n",
    "        mu = self.conv_mu(x).squeeze()\n",
    "        var = torch.exp(self.conv_var(x).squeeze())\n",
    "\n",
    "        return disc_logits, mu, var\n",
    "params = {\n",
    "    'batch_size': 128,         # Batch size.\n",
    "    'num_epochs': 100,         # Number of epochs \n",
    "    'learning_rate': 2e-4,     # Learning rate.\n",
    "    'beta1': 0.5,\n",
    "    'beta2': 0.999,\n",
    "    'save_epoch' : 25,\n",
    "    'dataset' : 'MNIST'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if(torch.cuda.is_available()) else \"cpu\")\n",
    "dataloader = get_data(params['dataset'], params['batch_size'])\n",
    "\n",
    "if(params['dataset'] == 'MNIST'):\n",
    "    params['num_z'] = 62\n",
    "    params['num_dis_c'] = 1\n",
    "    params['dis_c_dim'] = 10\n",
    "    params['num_con_c'] = 2\n",
    "elif(params['dataset'] == 'FashionMNIST'):\n",
    "    params['num_z'] = 62\n",
    "    params['num_dis_c'] = 1\n",
    "    params['dis_c_dim'] = 10\n",
    "    params['num_con_c'] = 2\n",
    "\n",
    "# Plot the training images.\n",
    "sample_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(\n",
    "    sample_batch[0].to(device)[ : 100], nrow=10, padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
    "plt.savefig('Training Images {}'.format(params['dataset']))\n",
    "plt.close('all')\n",
    "\n",
    "# Initialise the network.\n",
    "netG = Generator().to(device)\n",
    "netG.apply(weights_init)\n",
    "print(netG)\n",
    "\n",
    "discriminator = Discriminator().to(device)\n",
    "discriminator.apply(weights_init)\n",
    "print(discriminator)\n",
    "\n",
    "netD = DHead().to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)\n",
    "\n",
    "netQ = QHead().to(device)\n",
    "netQ.apply(weights_init)\n",
    "print(netQ)\n",
    "\n",
    "#Loss\n",
    "criterionD = nn.BCELoss()\n",
    "criterionQ_dis = nn.CrossEntropyLoss()\n",
    "criterionQ_con = NormalNLLLoss()\n",
    "\n",
    "# Adam optimiser is used.\n",
    "optimD = optim.Adam([{'params': discriminator.parameters()}, {'params': netD.parameters()}], lr=params['learning_rate'], betas=(params['beta1'], params['beta2']))\n",
    "optimG = optim.Adam([{'params': netG.parameters()}, {'params': netQ.parameters()}], lr=params['learning_rate'], betas=(params['beta1'], params['beta2']))\n",
    "\n",
    "# Fixed Noise\n",
    "z = torch.randn(100, params['num_z'], 1, 1, device=device)\n",
    "fixed_noise = z\n",
    "if(params['num_dis_c'] != 0):\n",
    "    idx = np.arange(params['dis_c_dim']).repeat(10)\n",
    "    dis_c = torch.zeros(100, params['num_dis_c'], params['dis_c_dim'], device=device)\n",
    "    for i in range(params['num_dis_c']):\n",
    "        dis_c[torch.arange(0, 100), i, idx] = 1.0\n",
    "\n",
    "    dis_c = dis_c.view(100, -1, 1, 1)\n",
    "\n",
    "    fixed_noise = torch.cat((fixed_noise, dis_c), dim=1)\n",
    "\n",
    "if(params['num_con_c'] != 0):\n",
    "    con_c = torch.rand(100, params['num_con_c'], 1, 1, device=device) * 2 - 1\n",
    "    fixed_noise = torch.cat((fixed_noise, con_c), dim=1)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "start_time = time.time()\n",
    "iters = 0\n",
    "\n",
    "for epoch in range(params['num_epochs']):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    for i, (data, _) in enumerate(dataloader, 0):\n",
    "        # Get batch size\n",
    "        b_size = data.size(0)\n",
    "        # Transfer data tensor to GPU/CPU (device)\n",
    "        real_data = data.to(device)\n",
    "\n",
    "        # Updating discriminator and DHead\n",
    "        optimD.zero_grad()\n",
    "        # Real data\n",
    "        label = torch.full((b_size, ), real_label, device=device)\n",
    "        output1 = discriminator(real_data)\n",
    "        probs_real = netD(output1).view(-1)\n",
    "        loss_real = criterionD(probs_real, label)\n",
    "        # Calculate gradients.\n",
    "        loss_real.backward()\n",
    "\n",
    "        # Fake data\n",
    "        label.fill_(fake_label)\n",
    "        noise, idx = noise_sample(params['num_dis_c'], params['dis_c_dim'], params['num_con_c'], params['num_z'], b_size, device)\n",
    "        fake_data = netG(noise)\n",
    "        output2 = discriminator(fake_data.detach())\n",
    "        probs_fake = netD(output2).view(-1)\n",
    "        loss_fake = criterionD(probs_fake, label)\n",
    "        # Calculate gradients.\n",
    "        loss_fake.backward()\n",
    "\n",
    "        # Net Loss for the discriminator\n",
    "        D_loss = loss_real + loss_fake\n",
    "        # Update parameters\n",
    "        optimD.step()\n",
    "\n",
    "        # Updating Generator and QHead\n",
    "        optimG.zero_grad()\n",
    "\n",
    "        # Fake data treated as real.\n",
    "        output = discriminator(fake_data)\n",
    "        label.fill_(real_label)\n",
    "        probs_fake = netD(output).view(-1)\n",
    "        gen_loss = criterionD(probs_fake, label)\n",
    "\n",
    "        q_logits, q_mu, q_var = netQ(output)\n",
    "        target = torch.LongTensor(idx).to(device)\n",
    "        # Calculating loss for discrete latent code.\n",
    "        dis_loss = 0\n",
    "        for j in range(params['num_dis_c']):\n",
    "            dis_loss += criterionQ_dis(q_logits[:, j*10 : j*10 + 10], target[j])\n",
    "\n",
    "        # Calculating loss for continuous latent code.\n",
    "        con_loss = 0\n",
    "        if (params['num_con_c'] != 0):\n",
    "            con_loss = criterionQ_con(noise[:, params['num_z']+ params['num_dis_c']*params['dis_c_dim'] : ].view(-1, params['num_con_c']), q_mu, q_var)*0.1\n",
    "\n",
    "        # Net loss for generator.\n",
    "        G_loss = gen_loss + dis_loss + con_loss\n",
    "        # Calculate gradients.\n",
    "        G_loss.backward()\n",
    "        # Update parameters.\n",
    "        optimG.step()\n",
    "\n",
    "        # Check progress of training.\n",
    "        if i != 0 and i%100 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
    "                  % (epoch+1, params['num_epochs'], i, len(dataloader), \n",
    "                    D_loss.item(), G_loss.item()))\n",
    "        G_losses.append(G_loss.item())\n",
    "        D_losses.append(D_loss.item())\n",
    "\n",
    "        iters += 1\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(\"Time taken for Epoch %d: %.2fs\" %(epoch + 1, epoch_time))\n",
    "    with torch.no_grad():\n",
    "        gen_data = netG(fixed_noise).detach().cpu()\n",
    "    img_list.append(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True))\n",
    "\n",
    "    # Generate image to check performance of generator.\n",
    "    if((epoch+1) == 1 or (epoch+1) % params['num_epochs']/10 == 0):\n",
    "        with torch.no_grad():\n",
    "            gen_data = netG(fixed_noise).detach().cpu()\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.transpose(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True), (1,2,0)))\n",
    "        plt.savefig(\"Epoch_%d {}\".format(params['dataset']) %(epoch+1))\n",
    "        plt.close('all')\n",
    "\n",
    "    # Save network\n",
    "    if (epoch+1) % params['save_epoch'] == 0:\n",
    "        torch.save({\n",
    "            'netG' : netG.state_dict(),\n",
    "            'discriminator' : discriminator.state_dict(),\n",
    "            'netD' : netD.state_dict(),\n",
    "            'netQ' : netQ.state_dict(),\n",
    "            'optimD' : optimD.state_dict(),\n",
    "            'optimG' : optimG.state_dict(),\n",
    "            'params' : params\n",
    "            }, 'checkpoint/model_epoch_%d_{}'.format(params['dataset']) %(epoch+1))\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print('Training finished!\\nTotal Time for Training: %.2fm' %(training_time / 60))\n",
    "\n",
    "# Generate image to check performance of trained generator.\n",
    "with torch.no_grad():\n",
    "    gen_data = netG(fixed_noise).detach().cpu()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True), (1,2,0)))\n",
    "plt.savefig(\"Epoch_%d_{}\".format(params['dataset']) %(params['num_epochs']))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
